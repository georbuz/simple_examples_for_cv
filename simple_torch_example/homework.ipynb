{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"0195eaab-2633-4fc4-9cb2-99a59c552dc0"},"cells":[{"cell_type":"markdown","source":"# CV part one\n\nВ этой тетрадке мы рассмотрим задачу распознавания лиц на примере датасета [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n\n**Предполагаем, что ноутбук запущен внутри Yandex DataSphere**","metadata":{"id":"cIu1b5Xo4Bdd","cellId":"38lqsetzmcbfb8lk82ubeg"}},{"cell_type":"code","source":"#!bash\nrm -r .\\tboard_logs","metadata":{"cellId":"x329g59m3genovmkgbwjpo","trusted":true},"outputs":[],"execution_count":1135},{"cell_type":"code","source":"from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport cv2\nimport os\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom torchvision.models import resnet34\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\")","metadata":{"id":"TyTa9uFb4Bdl","cellId":"212z2memf5cmplpkb5eb0s","trusted":true},"outputs":[],"execution_count":1005},{"cell_type":"markdown","source":"## Data\n\nКачаем архив с данными с Yandex Object Storage и распаковываем в текущую папку.\n\nСтруктура архива:\n- /celeba_data/\n    - train.csv\n    - val.csv\n    - images/{image}.jpg\n\nCSV файлы содержат название файла (`image`) и его лейбл (`label`).","metadata":{"id":"CiLnuFXG4Bdm","cellId":"rgra31480u3h8nfb7hzj4"}},{"cell_type":"code","source":"from cloud_ml.storage.api import Storage\n\ns3 = Storage.s3(access_key=\"Le9tg70HQEJsoGqjqXH8\", secret_key=\"NV75mCPkC0PEd35ImyDI5vI7p40YGFOYZgkH7moa\")\n# downloading contents of the remote file into the local one\ns3.get('dl-hse-2021/celeba_data.zip', './celeba_data.zip')","metadata":{"cellId":"bo51i7oqlpdb9m8dwn3spm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"\r"}],"execution_count":2},{"cell_type":"code","source":"#!:bash\nunzip -q ./celeba_data.zip -d ./ && rm celeba_data.zip","metadata":{"cellId":"mbja58q90lq40q6jedx575","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Задание 1\n**(0.2 балла)** Напишите класс датасет, который будет возвращать картинку и ее лейбл.","metadata":{"id":"i8b_O3Y94Bdq","cellId":"zrykja70wsr3sw184uq2t7"}},{"cell_type":"code","source":"class CelebADataset(Dataset):\n    def __init__(self, train=True):\n        self._path = \"celeba_data/\"\n        self.images_dir_path = self._path + \"images/\"\n        self.file = self._path + \"train.csv\" if train else self._path + \"val.csv\"\n        self.header = pd.read_csv(self.file)\n\n    def __len__(self):\n        return len(self.header)\n    \n    def __getitem__(self, index):\n        img_name, label = self.header.iloc[index, :]\n        \n        img_path = Path(self.images_dir_path, img_name)\n        img = self._read_img(img_path)\n        \n        return dict(sample=img, label=label)\n        \n    @staticmethod\n    def _read_img(img_path: Path):\n        img = cv2.imread(str(img_path.resolve()))\n        img = img.astype(np.float32)\n        img = np.transpose(img, (2, 0, 1)) / 255.\n        \n        return img","metadata":{"cellId":"oc7biaz3ye06kf75gvciv5","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Задание 2\n**(0.2 балла)** Напишите функцию, которая будет считать метрику top-n accuracy.\n\n$$TopN \\ Accuracy = \\frac{Number \\ of \\ objects \\ with \\ correct \\ answer \\ among \\ topN \\ predictions}{Total \\ number \\ of \\ objects}$$\n\n*Example:*\n\n![image](https://www.baeldung.com/wp-content/ql-cache/quicklatex.com-ae746981c7a437b7e1fc2831e5d76d57_l3.svg)  \n$Top3 \\ Accuracy = \\frac{4}{5} = 0.8$\n\n*Hint:* Для каждого объекта выбираем `n` наиболее уверенных предсказаний. Если среди них есть правильный ответ, то увеличиваем числитель и знаменатель на единицу, иначе увеличиваем только знаменатель.","metadata":{"id":"i8b_O3Y94Bdq","cellId":"42liqfoavi30iheofhu1m2"}},{"cell_type":"code","source":"def top_n_accuracy(preds: np.ndarray,\n                   targets: np.ndarray,\n                   n_size: int) -> float:\n    \"\"\"\n    Предполагается, что на preds приходит на вход в порядке убывания уверенности предсказания\n    Так же предполагаем, что уже убраны дубликаты\n    \"\"\"\n    return (targets.reshape(-1, 1) == preds[:, :n_size]).any(axis=1).mean()","metadata":{"cellId":"6btuqm12a69cz6fgag1coi","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"targets = np.array([1, 0, 2, 2])\npreds = np.array([\n    [1, 0, 3],\n    [3, 4, 0],\n    [0, 2, 3],\n    [3, 4, 2]\n])\n\nassert top_n_accuracy(preds, targets, 2) == 2 / 4","metadata":{"cellId":"b6mqrd0cz5ul4sfntcc73e","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Задание 3\n**(0.2 балла)** Решите задачу без дообучения.\n\n*Step-by-step:*\n1. Инициализируйте предобученную сетку (`backbone`).\n1. Прогоните через нее все картинки из валидационного датасета и сложите полученные эмбеддинги в массив.\n1. Для каждого вектора найдите ближайшие к нему векторы и отсортируйте их по расстоянию (cosine, euclidian, ...). Лейблы соседних векторов будут предсказаниями для текущего вектора.\n1. Оставьте топ-5 уникальных предсказаний.\n1. Посчитайте и выведите метрики:\n    1. top-1 accuracy\n    1. top-5 accuracy\n\n*Вопросы:*\n1. Зачем мы заменяем последний линейный слой на `Identity` ?\n1. Зачем используем на сетке метод `eval` ?\n\n*Hints:*\n1. Для расчета попарных расстояний лучше не использовать циклы, а считать все в матрицах. Описание подхода к расчету L2 расстояний: [link](https://math.stackexchange.com/questions/3147549/compute-the-pairwise-euclidean-distance-matrix)\n1. Так можно использовать sklearn реализации: [link](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise)\n1. Для получения top-k предсказаний не обязательно сортировать весь массив.","metadata":{"id":"i8b_O3Y94Bdq","cellId":"jgagu11ef1hwupvrwohxk"}},{"cell_type":"markdown","source":"*Ответы:*\n\n1. Identity - пропускает выходы последнего слоя as is. В этой задаче не нужна голова-классификатор, достаточно будет скоров/эмбедингов бэкбона\n1. Некоторые блоки сети по разному ведут себя на трейне и инференсе, методом `eval()` мы переключаем их на режим инференса","metadata":{"cellId":"bs62kl6eqbdzovkrwydknc"}},{"cell_type":"code","source":"#!L\n\nDEVICE = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n\nbackbone = resnet34(pretrained=True)\nbackbone.fc = nn.Identity()\nbackbone = backbone.eval()\nbackbone.to(DEVICE)\n\nceleb_val = DataLoader(CelebADataset(train=False), shuffle=False, pin_memory=True)","metadata":{"cellId":"yl7xyupggogu5wlbmxurgn","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#!L\n\n@torch.no_grad()\ndef get_embeds(model: nn.Module, dataloader: DataLoader) -> np.ndarray:\n    embeddings = []\n    labels = []\n    model.eval()\n    for batch in tqdm(dataloader):\n        embedding = model.forward(batch[\"sample\"].to(DEVICE))\n        embeddings.append(embedding.cpu().numpy())\n        labels.append(batch[\"label\"].cpu().numpy())\n        torch.cuda.empty_cache()\n    \n    return np.concatenate(embeddings), np.concatenate(labels)\n\n\ndef l2_dist(x: np.ndarray) -> np.ndarray:\n    # своровано с лекции\n    a = x.dot(x.T)\n    b = np.diag(a)\n    dist = np.sqrt(b.reshape(-1, 1) - 2 * a + b)\n    return dist\n\nembeds, labels = get_embeds(backbone, celeb_val)\n\ndists = l2_dist(embeds)\n\nnp.save(\"val_embeds.npy\", embeds)\nnp.save(\"val_labels.npy\", labels)\nnp.save(\"val_dists.npy\", dists)","metadata":{"cellId":"uxrrgwnvhfrc0get2gf2op","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 19867/19867 [04:59<00:00, 66.25it/s]\n"}],"execution_count":6},{"cell_type":"code","source":"#!M\n# embeds = np.load(\"embeds.npy\")\n# dists  = np.load(\"dists.npy\")\ndef top_n_preds(labels, dists, n):\n    \"\"\" Отбор top-n уникальных предсказаний\"\"\"\n    sorted_preds = labels[np.argsort(dists, axis=1)][:, 1:]\n    # https://stackoverflow.com/questions/12926898/numpy-unique-without-sort\n    top_n_preds = []\n    for row in sorted_preds:\n        indexes = np.unique(row, return_index=True)[1]\n        preds = [row[index] for index in sorted(indexes)]\n        top_n_preds.append(preds[:n])\n    return np.array(top_n_preds)\n\ndef compute_accs(labels, dists, n=[1, 5]):\n    top_preds = top_n_preds(labels, dists, max(n))\n    accs = [top_n_accuracy(top_preds, labels, n_) for n_ in n]\n    return accs\n    \nbaseline_top_1_acc, baseline_top_5_acc = compute_accs(labels, dists)\n\nprint(f\"TOP 1 ACCURACY: %.3f\" % baseline_top_1_acc)\nprint(f\"TOP 5 ACCURACY: %.3f\" % baseline_top_5_acc)","metadata":{"cellId":"ecxrrokdzdtg0o03594xv","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"TOP 1 ACCURACY: 0.160\nTOP 5 ACCURACY: 0.273\n"}],"execution_count":13},{"cell_type":"markdown","source":"## Задание 4\n**(0.4 балла)** Решите задачу с дообучением на эмбеддингах.\n\n*Step-by-step:*\n1. Напишите небольшую сетку произвольной архитектуры, которая будет использовать эмбеды, выдаваемые `backbone` сетью.\n1. Напишите класс Dataset, который будет возвращать эмбединг и лейбл.\n1. Напишите класс Sampler [PyTroch docs](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler), который будет отвечать за правильность сбора тренировочных батчей: якорный пример, позитивный, негативный.\n1. Обучите ее на тренировочном датасете:\n    1. Лосс -- [triplet loss](https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html).\n    1. Метрика -- top-5 accuracy.\n1. Посчитайте top-1 и top-5 accuracy на валидации. Насколько сильно они отличаются от того, что получилось в предыдущем задании?\n\n\n*Hints:*\n1. Убедитесь, что у каждого лейбла есть как минимум 2 примера, иначе не получится достать позитивный пример.\n1. Лучше предварительно прогнать все картинки из трейна и сохранить полученные эмбеддинги, чтобы при обучении сети грузить только эмбеды (векторы).","metadata":{"id":"i8b_O3Y94Bdq","cellId":"qyxj31ya2qg7ht7gehbftk"}},{"cell_type":"code","source":"#!L\n# сразу доформируем эмбеды\n\nceleb_train = DataLoader(CelebADataset(train=True), shuffle=False, pin_memory=True)\n\ntrain_embeds, train_labels = get_embeds(backbone, celeb_train)\n\nnp.save(\"train_embeds.npy\", train_embeds)\nnp.save(\"train_labels.npy\", train_labels)","metadata":{"cellId":"us1usoehrak03je3xcdjkwo","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 162770/162770 [40:17<00:00, 67.32it/s]\n"}],"execution_count":14},{"cell_type":"code","source":"#!L\n\nclass SimpleDataset(Dataset):\n    def __init__(self, embeddings: torch.tensor,\n                 labels: torch.tensor):\n\n        self.embeddings = embeddings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        if isinstance(idx, int):\n            sample = self.embeddings[idx]\n            label = self.labels[idx]\n            \n            return dict(\n                sample=sample,\n                label=label\n            )\n        else:\n            assert len(idx) == 3\n            \n            anc_idx, pos_idx, neg_idx = idx\n            \n            samples = self.embeddings[anc_idx], self.embeddings[pos_idx], self.embeddings[neg_idx]\n            labels  = self.labels[anc_idx],     self.labels[pos_idx],     self.labels[neg_idx]\n\n            return dict(\n                samples=samples,\n                labels=labels\n            )\n\n\nclass SimpleTripletSampler(Sampler):\n    def __init__(self, dataset: Dataset):\n        super().__init__(dataset)\n\n        self.dataset = dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __iter__(self):\n        for anchor_idx in range(len(self.dataset)):\n            positive_idx = self._mine_positive(anchor_idx)\n            negative_idx = self._mine_negative(anchor_idx)\n\n            yield anchor_idx, positive_idx, negative_idx\n\n    def _mine_positive(self, anchor_idx: int):\n\n        anchor_label = self.dataset.labels[anchor_idx]\n        pos_idxs = torch.nonzero(self.dataset.labels == anchor_label)\n        pos_idx = pos_idxs[np.random.randint(low=0, high=pos_idxs.shape[0])]\n        \n        if len(pos_idxs) == 1:\n            return anchor_idx\n\n        return pos_idx.squeeze()\n\n    def _mine_negative(self, anchor_idx: int):\n\n        anchor_label = self.dataset.labels[anchor_idx]\n        neg_idxs = torch.nonzero(self.dataset.labels != anchor_label)\n        neg_idx = neg_idxs[np.random.randint(low=0, high=neg_idxs.shape[0])]\n\n        return neg_idx.squeeze()\n\n# sanity check\ndef sanity():\n    train_embdes = torch.tensor(np.load(\"train_embeds.npy\"), device=DEVICE)\n    train_labels = torch.tensor(np.load(\"train_labels.npy\"), device=DEVICE)\n    dataset = SimpleDataset(train_embeds, train_labels)\n    sampler = SimpleTripletSampler(dataset)\n    loader  = DataLoader(dataset=dataset, sampler=sampler, batch_size=10)\n    \n    batch = next(iter(loader))\n    print(batch[\"samples\"][0])\n    print(batch[\"samples\"][1])\n    print(batch[\"samples\"][2])\n    \n    assert (batch[\"labels\"][0] == batch[\"labels\"][1]).all(), 'Positive labels dont match'\n    assert (batch[\"labels\"][0] != batch[\"labels\"][2]).all(), 'Negative labels dont mismatch'\n    print(\"Success!\")\n    \nsanity()","metadata":{"cellId":"99smq7yktzkm14zcrmzs6","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[1.8756e+00, 4.5872e-01, 5.4045e-01,  ..., 1.0325e+00, 1.3787e+00,\n         4.7378e-01],\n        [1.1979e+00, 4.4343e-01, 3.5210e-04,  ..., 5.4469e-01, 1.6519e-01,\n         3.5330e-01],\n        [1.4011e+00, 3.4878e-01, 5.1260e-01,  ..., 1.3276e+00, 3.9931e-01,\n         1.5838e+00],\n        ...,\n        [1.2097e+00, 1.2873e+00, 8.8493e-01,  ..., 8.3415e-01, 9.1353e-02,\n         5.1008e-01],\n        [1.2309e+00, 2.1698e-01, 0.0000e+00,  ..., 5.6329e-01, 5.8289e-01,\n         1.2876e+00],\n        [1.0101e+00, 6.1693e-01, 8.3480e-01,  ..., 1.1601e+00, 3.7407e-01,\n         1.0441e+00]])\ntensor([[1.2422, 0.6934, 0.2338,  ..., 1.4113, 0.0898, 1.0202],\n        [1.5253, 0.2900, 0.7709,  ..., 2.3567, 0.4107, 0.8077],\n        [1.4011, 0.3488, 0.5126,  ..., 1.3276, 0.3993, 1.5838],\n        ...,\n        [0.5586, 0.3096, 0.5893,  ..., 0.8518, 1.5713, 1.4221],\n        [1.2309, 0.2170, 0.0000,  ..., 0.5633, 0.5829, 1.2876],\n        [1.0467, 0.6908, 0.2539,  ..., 1.6227, 0.2793, 0.7280]])\ntensor([[0.8822, 0.3201, 1.1676,  ..., 1.7045, 1.3391, 1.0997],\n        [2.2080, 0.6475, 0.3464,  ..., 1.1646, 0.3274, 0.9640],\n        [0.3864, 0.8944, 0.7250,  ..., 0.8086, 0.3643, 0.6628],\n        ...,\n        [0.7718, 0.3407, 0.5789,  ..., 2.1260, 0.5563, 1.2884],\n        [1.2166, 0.4774, 0.5449,  ..., 1.3201, 0.5358, 0.7426],\n        [0.9211, 0.2640, 0.2268,  ..., 1.1480, 0.2342, 1.4272]])\nSuccess!\n"}],"execution_count":1078},{"cell_type":"code","source":"#!L\n\nclass SomeModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n                        nn.Linear(in_features=512, out_features=1024),\n                        nn.ReLU(),\n                        nn.Linear(in_features=1024, out_features=1024),\n                        nn.ReLU(),\n                        nn.Linear(in_features=1024, out_features=512),\n                    )\n        self.triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n    \n    def forward(self, triplet):\n#         print(self.triplet_loss(*triplet))\n        anchor   = self.net(triplet[0])\n        positive = self.net(triplet[1])\n        negative = self.net(triplet[2])\n#         print(\"3 \", anchor, positive, negative)\n        return anchor, positive, negative\n        \n    \n    def compute_all(self, triplet, labels):\n        # computes batch-wise loss and accuracy\n        loss = self.triplet_loss(*triplet)\n        \n        all_embeds = torch.cat(triplet).cpu().detach().numpy()\n        all_labels = torch.cat(labels).cpu().detach().numpy()\n        \n        dists = l2_dist(all_embeds)\n#         print(\"0 \", len(labels[0]), all_labels.shape, all_embeds.shape, triplet[0].shape)\n        accs = compute_accs(all_labels, dists)\n        \n        return loss, dict(acc_1=accs[0], acc_5=accs[1])","metadata":{"cellId":"kzrrk9q4vyfys2x1c33","trusted":true},"outputs":[],"execution_count":1125},{"cell_type":"code","source":"#!L\n\ndef set_seed(seed):\n    # https://stackoverflow.com/questions/56354461/reproducibility-and-performance-in-pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)    \n\nset_seed(12)\n\n\nclass Trainer:\n    def __init__(self, model: nn.Module,\n                 optimizer,\n                 train_dataset: Dataset,\n                 val_dataset: Dataset,\n                 tboard_log_dir: str = \"./tboard_logs/\",\n                 batch_size: int = 128,\n                 n_hardest: int = 256):\n        self.model = model\n        self.optimizer = optimizer\n#         self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n        self.train_dataset = train_dataset\n        self.val_dataset = val_dataset\n        self.batch_size = batch_size\n        self.train_sampler = SimpleTripletSampler(train_dataset)\n        self.val_sampler = SimpleTripletSampler(val_dataset)\n        self.hard_selector = nn.TripletMarginLoss(margin=1.0, p=2, reduction='none')\n        self.n_hardest = n_hardest\n        self.device = 'cpu'\n        if torch.cuda.is_available():\n            self.device = torch.cuda.current_device()\n            self.model = self.model.to(self.device)\n\n        self.global_step = 0\n        self.train_writer = SummaryWriter(log_dir=tboard_log_dir + \"train/\")\n        self.val_writer = SummaryWriter(log_dir=tboard_log_dir + \"val/\")\n        \n        \n    def save_checkpoint(self, path):\n        torch.save(self.model.state_dict(), path)\n        \n    @torch.no_grad()\n    def select_hardest(self, triplet):\n#         print(\"1 \", triplet)\n        hard_idxs = self.hard_selector(*triplet)\n#         print(\"2 \", hard_idxs)\n        hard_idxs = list(hard_idxs.topk(self.n_hardest).indices.detach().cpu().numpy())\n        \n        return hard_idxs\n\n    def train(self, num_epochs: int):\n        model = self.model\n        optimizer = self.optimizer\n\n        train_loader = DataLoader(self.train_dataset, sampler=self.train_sampler, batch_size=self.batch_size)\n        val_loader = DataLoader(self.val_dataset, sampler=self.val_sampler, batch_size=self.batch_size)\n        best_loss = float('inf')\n\n        for epoch in range(num_epochs):\n            model.train()\n            train_losses = []\n            for batch in tqdm(train_loader):\n#                 print(batch[\"samples\"][0].shape)\n                batch = {k: [v_.to(self.device) for v_ in v] for k, v in batch.items()}\n                samples, labels = batch[\"samples\"], batch[\"labels\"]\n#                 print(\"-1 \", batch[\"samples\"][0].shape, batch[\"labels\"][0].shape)\n                samples = model.forward(samples)\n                \n                hardest_idxs = self.select_hardest(samples)\n                labels = labels[0][hardest_idxs], labels[1][hardest_idxs], labels[2][hardest_idxs]\n                samples = samples[0][hardest_idxs], samples[1][hardest_idxs], samples[2][hardest_idxs]\n\n                loss, details = model.compute_all(samples, labels)\n                train_losses.append(loss.item())\n                \n                for k, v in details.items():\n                    self.train_writer.add_scalar(k, v, global_step=self.global_step)\n                self.global_step += 1\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                \n            mean_train_loss = np.mean(train_losses)\n\n            model.eval()\n            val_losses = []\n            val_logs = defaultdict(list)\n            for batch in tqdm(val_loader):\n                batch = {k: [v_.to(self.device) for v_ in v] for k, v in batch.items()}\n                \n                samples, labels = batch[\"samples\"], batch[\"labels\"]\n                samples = model.forward(samples)\n                \n                loss, details = model.compute_all(samples, labels)\n                val_losses.append(loss.item())\n                for k, v in details.items():\n                    val_logs[k].append(v)\n                    \n            val_logs = {k: np.mean(v) for k, v in val_logs.items()}\n            for k, v in val_logs.items():\n                self.val_writer.add_scalar(k, v, global_step=self.global_step)\n\n            val_loss = np.mean(val_losses)\n            \n            if val_loss < best_loss:\n                self.save_checkpoint(\"./best_checkpoint.pth\")\n                best_loss = val_loss\n            \n            print(\"Batch mean train Loss:  %.4f\\tBatch mean val Loss:  %.4f\" % (mean_train_loss, val_loss))\n            \n#             self.scheduler.step(val_loss)","metadata":{"cellId":"60qgonlec3fzh4s4h38m4i","trusted":true},"outputs":[],"execution_count":1126},{"cell_type":"code","source":"#!L\n\ntrain_set = SimpleDataset(\n                    torch.tensor(np.load(\"train_embeds.npy\"), device=DEVICE, requires_grad=True), \n                    torch.tensor(np.load(\"train_labels.npy\"), device=DEVICE, requires_grad=False)\n            )\nval_set   = SimpleDataset(\n                    torch.tensor(np.load(\"val_embeds.npy\"), device=DEVICE, requires_grad=True), \n                    torch.tensor(np.load(\"val_labels.npy\"), device=DEVICE, requires_grad=False)\n            )\n\nmodel = SomeModel()\nopt = optim.Adam(model.parameters(), lr=1e-4)\ntrainer = Trainer(model, opt, train_set, val_set, batch_size=1024, n_hardest=700)\n\ntrainer.train(20)\n\n@torch.no_grad()\ndef em():\n    embeddings = []\n    labels = []\n    model.eval()\n    for batch in tqdm(DataLoader(val_set, shuffle=False)):\n        embedding = model.net(batch[\"sample\"].to(DEVICE))\n        embeddings.append(embedding.cpu().numpy())\n        labels.append(batch[\"label\"].cpu().numpy())\n        torch.cuda.empty_cache()\n    \n    return np.concatenate(embeddings), np.concatenate(labels)\n\n\nnew_embeds, new_labels = em()\nnew_dists = l2_dist(new_embeds)\ntop_1_acc, top_5_acc = compute_accs(new_labels, new_dists)\n\nprint(f\"TOP 1 ACCURACY: %.3f\" % top_1_acc)\nprint(f\"TOP 5 ACCURACY: %.3f\" % top_5_acc)","metadata":{"cellId":"dixad8qsxg9mz4dfzlzria","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Batch mean train Loss:  0.6256\tBatch mean val Loss:  0.3732\nBatch mean train Loss:  0.5260\tBatch mean val Loss:  0.3403\nBatch mean train Loss:  0.5044\tBatch mean val Loss:  0.3268\nBatch mean train Loss:  0.4856\tBatch mean val Loss:  0.3171\nBatch mean train Loss:  0.4721\tBatch mean val Loss:  0.3229\nBatch mean train Loss:  0.4644\tBatch mean val Loss:  0.3170\nBatch mean train Loss:  0.4530\tBatch mean val Loss:  0.3070\nBatch mean train Loss:  0.4447\tBatch mean val Loss:  0.3086\nBatch mean train Loss:  0.4408\tBatch mean val Loss:  0.3077\nBatch mean train Loss:  0.4359\tBatch mean val Loss:  0.3030\nBatch mean train Loss:  0.4306\tBatch mean val Loss:  0.3002\nBatch mean train Loss:  0.4290\tBatch mean val Loss:  0.2930\nBatch mean train Loss:  0.4246\tBatch mean val Loss:  0.3002\nBatch mean train Loss:  0.4170\tBatch mean val Loss:  0.3037\nBatch mean train Loss:  0.4188\tBatch mean val Loss:  0.2882\nBatch mean train Loss:  0.4124\tBatch mean val Loss:  0.2915\nBatch mean train Loss:  0.4083\tBatch mean val Loss:  0.2930\nBatch mean train Loss:  0.4034\tBatch mean val Loss:  0.2911\nBatch mean train Loss:  0.4016\tBatch mean val Loss:  0.2836\nBatch mean train Loss:  0.3962\tBatch mean val Loss:  0.2922\nTOP 1 ACCURACY: 0.162\nTOP 5 ACCURACY: 0.321\n"},{"output_type":"stream","name":"stderr","text":"  0%|          | 0/159 [00:00<?, ?it/s]/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:53: UserWarning: This overload of nonzero is deprecated:\n\tnonzero(Tensor input, *, Tensor out)\nConsider using one of the following signatures instead:\n\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n  if ATTACH_DEBUGGER:\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:19: RuntimeWarning: invalid value encountered in sqrt\n  \n100%|██████████| 159/159 [24:02<00:00,  9.07s/it]\n100%|██████████| 20/20 [01:25<00:00,  4.26s/it]\n100%|██████████| 159/159 [23:49<00:00,  8.99s/it]\n100%|██████████| 20/20 [01:25<00:00,  4.29s/it]\n100%|██████████| 159/159 [23:49<00:00,  8.99s/it]\n100%|██████████| 20/20 [01:25<00:00,  4.28s/it]\n100%|██████████| 159/159 [23:59<00:00,  9.05s/it]\n100%|██████████| 20/20 [01:31<00:00,  4.58s/it]\n100%|██████████| 159/159 [24:02<00:00,  9.07s/it]\n100%|██████████| 20/20 [01:26<00:00,  4.32s/it]\n100%|██████████| 159/159 [24:01<00:00,  9.07s/it]\n100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n100%|██████████| 159/159 [23:58<00:00,  9.05s/it]\n100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n100%|██████████| 159/159 [23:58<00:00,  9.05s/it]\n100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n100%|██████████| 159/159 [24:01<00:00,  9.07s/it]\n100%|██████████| 20/20 [01:27<00:00,  4.36s/it]\n100%|██████████| 159/159 [23:58<00:00,  9.05s/it]\n100%|██████████| 20/20 [01:26<00:00,  4.33s/it]\n100%|██████████| 159/159 [24:02<00:00,  9.08s/it]\n100%|██████████| 20/20 [01:34<00:00,  4.70s/it]\n100%|██████████| 159/159 [24:16<00:00,  9.16s/it]\n100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\n100%|██████████| 159/159 [24:17<00:00,  9.17s/it]\n100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\n100%|██████████| 159/159 [24:19<00:00,  9.18s/it]\n100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\n100%|██████████| 159/159 [24:16<00:00,  9.16s/it]\n100%|██████████| 20/20 [01:29<00:00,  4.48s/it]\n100%|██████████| 159/159 [24:18<00:00,  9.17s/it]\n100%|██████████| 20/20 [01:29<00:00,  4.50s/it]\n100%|██████████| 159/159 [24:17<00:00,  9.17s/it]\n100%|██████████| 20/20 [01:29<00:00,  4.48s/it]\n100%|██████████| 159/159 [24:16<00:00,  9.16s/it]\n100%|██████████| 20/20 [01:29<00:00,  4.46s/it]\n100%|██████████| 159/159 [24:07<00:00,  9.10s/it]\n100%|██████████| 20/20 [01:30<00:00,  4.51s/it]\n100%|██████████| 159/159 [23:59<00:00,  9.05s/it]\n100%|██████████| 20/20 [01:25<00:00,  4.28s/it]\n100%|██████████| 19867/19867 [00:10<00:00, 1948.80it/s]\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:815: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":1127},{"cell_type":"code","source":"#!L\n\n# на последок загрузим лучшие веса\n@torch.no_grad()\ndef em():\n    embeddings = []\n    labels = []\n    \n    model.load_state_dict(torch.load(\"best_checkpoint.pth\"))\n    model.eval()\n    \n    for batch in tqdm(DataLoader(val_set, shuffle=False)):\n        embedding = model.net(batch[\"sample\"].to(DEVICE))\n        embeddings.append(embedding.cpu().numpy())\n        labels.append(batch[\"label\"].cpu().numpy())\n        torch.cuda.empty_cache()\n    \n    return np.concatenate(embeddings), np.concatenate(labels)\n\nnew_embeds, new_labels = em()\nnew_dists = l2_dist(new_embeds)\ntop_1_acc, top_5_acc = compute_accs(new_labels, new_dists)\n\n# но лучше особо не стало\nprint(f\"TOP 1 ACCURACY: %.3f\" % top_1_acc)\nprint(f\"TOP 5 ACCURACY: %.3f\" % top_5_acc)","metadata":{"cellId":"mszb3bzyfzfc7sj9xx7h7","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 19867/19867 [00:10<00:00, 1929.25it/s]\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:19: RuntimeWarning: invalid value encountered in sqrt\n  \n"},{"output_type":"stream","name":"stdout","text":"TOP 1 ACCURACY: 0.161\nTOP 5 ACCURACY: 0.318\n"}],"execution_count":1129},{"cell_type":"code","source":"# your code must be before example","metadata":{"cellId":"5lr9yul9izkgcxl55jdqjv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for final checkpoint","metadata":{"cellId":"d51dh04wohqxn8mjgbpqxl","trusted":true},"outputs":[],"execution_count":1131},{"cell_type":"markdown","source":"## Sampler (simple example)\n\nВ блоках ниже реализован пример датасета и сэмлера, который возвращает индексы для триплет лосса.\n\nДатасет написан топорно, но основная логика следующая. Если ему на вход приходит `int`, то он возвращает название картинки (`img_name`) и ее лейбл (`img_label`). Если же приходит нечто длиной 3, то он возвращает 3 названия картинок, соответственно. В нашем случае это будет три картинки с двумя одинаковыми лейблами и одним другим: anchor, positive, negative.  \nСэмплер `SimpleTripletSampler`, в свою очередь, отвечает за формирование и поставку в датасет индексов триплетов.\n\nДатасет и сэмлер объединяются внутри даталоадера.\n\n*Hint:* Код написан только лишь для примера, поэтому логика возвращения триплетов может быть неверной.","metadata":{"cellId":"qmk3j5diof9try6p5pv3kh"}},{"cell_type":"code","source":"class SimpleDataset(Dataset):\n    def __init__(self, img_names: np.ndarray,\n                 img_labels: np.ndarray):\n        if len(img_names) != len(img_labels):\n            raise ValueError('img_names and img_labels must have equal number of elements')\n\n        self.img_names = img_names\n        self.img_labels = img_labels\n\n    def __len__(self):\n        return len(self.img_names)\n    \n    def __getitem__(self, idx):\n        if isinstance(idx, int):\n            img_name = self.img_names[idx]\n            img_label = self.img_labels[idx]\n            \n            return img_name, img_label\n        else:\n            assert len(idx) == 3\n            \n            anc_idx, pos_idx, neg_idx = idx\n            anc_img_name = self.img_names[anc_idx]\n            pos_img_name = self.img_names[pos_idx]\n            neg_img_name = self.img_names[neg_idx]\n\n            return anc_img_name, pos_img_name, neg_img_name\n\n\nclass SimpleTripletSampler(Sampler):\n    def __init__(self, dataset: Dataset):\n        super().__init__(dataset)\n\n        self.dataset = dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __iter__(self):\n        for anchor_idx in range(len(self.dataset)):\n            positive_idx = self._mine_positive(anchor_idx)\n            negative_idx = self._mine_negative(anchor_idx)\n\n            yield anchor_idx, positive_idx, negative_idx\n\n    def _mine_positive(self, anchor_idx: int):\n        labels: np.ndarray = self.dataset.img_labels\n\n        anchor_label = labels[anchor_idx]\n        pos_idxs = np.nonzero(labels == anchor_label)[0]\n        pos_idx = np.random.choice(pos_idxs)\n\n        return pos_idx\n\n    def _mine_negative(self, anchor_idx: int):\n        labels: np.ndarray = self.dataset.img_labels\n\n        anchor_label = labels[anchor_idx]\n        neg_idxs = np.nonzero(labels != anchor_label)[0]\n        neg_idx = np.random.choice(neg_idxs)\n\n        return neg_idx","metadata":{"cellId":"03biv2ae8tcdrmqcc7q0p","trusted":true},"outputs":[],"execution_count":445},{"cell_type":"code","source":"ex_size = 100\nnp.random.seed(42)\n\n# в нашем примере названием картинки будет выступать число от 0 до 99, а лейблом число от 0 до 4.\nex_dataset = SimpleDataset(img_names=np.arange(ex_size),\n                           img_labels=np.random.randint(0, 5, size=ex_size))\nex_sampler = SimpleTripletSampler(dataset=ex_dataset)\n\nex_loader = DataLoader(dataset=ex_dataset, batch_size=10, sampler=ex_sampler)","metadata":{"cellId":"f6tcl0cqlac5e4eqk52ol","trusted":true},"outputs":[],"execution_count":446},{"cell_type":"code","source":"# В этой ячейке мы дергаем первый батч с названиями картинок и достаем их лейблы, \n#  чтобы проверить действительно ли у них одинаковые или разные лейблы.\n# Для тренировки сети с триплет лоссом сами лейблы нам не нужны будут.\n#  Главное чтобы триплеты картинок формировались правильно: anchor, positive, negative\n\nex_batch = next(iter(ex_loader))\n\nex_batch_anc_labels = ex_dataset.img_labels[ex_batch[0]]\nex_batch_pos_labels = ex_dataset.img_labels[ex_batch[1]]\nex_batch_neg_labels = ex_dataset.img_labels[ex_batch[2]]","metadata":{"cellId":"8z6lx8z9q1s0npxi2edxuz","trusted":true},"outputs":[],"execution_count":447},{"cell_type":"code","source":"torch.nonzero()","metadata":{"cellId":"8ka6nd0mimjybzqf8amy7s","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"array([1, 3, 3, 3, 2, 3, 1, 4, 1, 0])"},"metadata":{}}],"execution_count":448},{"cell_type":"code","source":"print('All anchor and positive labels are equal:', np.all(ex_batch_anc_labels == ex_batch_pos_labels))\nprint('Any of anchor and negative labels are equal:', np.any(ex_batch_anc_labels == ex_batch_neg_labels))","metadata":{"cellId":"vxcfeoyptv0eboo06ouk96","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"All anchor and positive labels are equal: True\nAny of anchor and negative labels are equal: False\n"}],"execution_count":449}]}